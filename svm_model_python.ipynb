{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cb5974-6621-46d2-85be-63ccc8b7307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadeu\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation des données en train et test...\n",
      "Normalisation\n",
      "Entrainement du modèle...\n",
      "Fin de l'entrainement\n",
      "sauvegarde du modèle\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pickle\n",
    "\n",
    "print('Chargement des données...')\n",
    "# Charger le dataset \"digits\"\n",
    "#digits = load_digits()\n",
    "#x, y = digits['data'], digits['target']\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "x = x/255\n",
    "\n",
    "# Division des données en train et test\n",
    "print('Séparation des données en train et test...')\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size = 60000,test_size=10000, random_state=42\n",
    ")\n",
    "\n",
    "# Normalisation\n",
    "print(\"Normalisation\")\n",
    "#scaler = StandardScaler()\n",
    "#x_train = scaler.fit_transform(x_train)\n",
    "#x_test = scaler.transform(x_test)  # Ici, on n'utilise pas fit_transform sur x_test pour éviter de faire \"le fit\" sur les données de test\n",
    "\n",
    "print('Entrainement du modèle...')\n",
    "# Construction du pipeline pour normalisation et SVM\n",
    "model = SVC(C=5, kernel='rbf', gamma=0.001)\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Fin de l'entrainement\")\n",
    "\n",
    "# Évaluation du modèle avec cross-validation\n",
    "#scores = cross_val_score(model, x_train, y_train, cv=5)\n",
    "#print(\"Scores de validation croisée : \", scores)\n",
    "#print(\"Score moyen : \", scores.mean())\n",
    "#print(x_test.shape)\n",
    "#print(y_test)\n",
    "\n",
    "print(\"sauvegarde du modèle\")\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81759cec-2b70-445c-8588-12df51a9e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecteurs de support:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "taille\n",
      "(14447, 784)\n",
      "coefficients:\n",
      " [[ 0.          0.          0.         ... -0.         -0.\n",
      "  -0.        ]\n",
      " [ 0.          0.          5.         ... -0.         -0.\n",
      "  -1.36754528]\n",
      " [ 0.          0.          0.         ... -0.         -5.\n",
      "  -0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -0.         -0.\n",
      "  -0.        ]\n",
      " [ 0.          0.          0.         ... -0.         -0.\n",
      "  -0.        ]\n",
      " [ 0.          0.          0.         ... -5.         -1.94299199\n",
      "  -0.        ]]\n",
      "bias:\n",
      " [ 0.57638115 -1.21452115 -0.5318417   0.56271783 -1.76393478  0.28083969\n",
      " -0.62770402  0.78785975  0.16280448 -2.28095315 -2.28961069  1.06946806\n",
      " -2.38327103  0.11461234 -0.61678807  3.06534261  0.5414132   1.13914563\n",
      "  2.14828731 -0.46636981  3.21276464  1.85501112  6.72823034  2.02431663\n",
      "  2.07028918 -2.90094214  1.65704444 -0.40440039  6.67010807  1.6487383\n",
      " -2.42970216 -0.35585876 -1.93910131 -0.60306931 -0.94243214  3.30103261\n",
      "  0.82275507  9.50451886  2.9359053  -0.5068642   0.44110867 -0.35724609\n",
      "  1.62143126  4.34618635 -1.5908001 ]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "filename = 'finalized_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#recupérons les coefficients du svm à noyau RBF\n",
    "#vecteurs de supports\n",
    "vecteurs_supports = model.support_vectors_\n",
    "#coefficients de chaque classe\n",
    "coefficients = model.dual_coef_\n",
    "#le bias\n",
    "biais = model.intercept_\n",
    "\n",
    "print(\"vecteurs de support:\\n\",vecteurs_supports)\n",
    "print(\"taille\")\n",
    "print(vecteurs_supports.shape)\n",
    "print(\"coefficients:\\n\",coefficients)\n",
    "print(\"bias:\\n\",biais)\n",
    "\n",
    "np.savetxt(\"vecteurs_support.txt\",vecteurs_supports)\n",
    "np.savetxt(\"coefficients.txt\",coefficients)\n",
    "np.savetxt(\"biais.txt\",biais)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79907dd-31e3-4db3-87bc-e954aad47bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label réel: 5\n",
      "Label prédit: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadeu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_index = 65\n",
    "true_label = y_test.iloc[prediction_index]  # Conversion en tableau NumPy\n",
    "#true_label = y_test[prediction_index]  # Conversion en tableau NumPy\n",
    "example = x_test.iloc[prediction_index]\n",
    "\n",
    "predicted_label = model.predict([example])[0]\n",
    "print(f\"Label réel: {true_label}\")\n",
    "print(f\"Label prédit: {predicted_label}\")\n",
    "\n",
    "# Affichage de l'image associée\n",
    "#example_image = example.reshape(28, 28)\n",
    "#plt.imshow(example_image, cmap=\"binary\", interpolation='nearest')\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "# Affichage d'une image d'exemple\n",
    "plt.imshow(np.array(example).reshape(28, 28), cmap=\"binary\", interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e2f48-d03f-4aab-83a9-8f5525bcc16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a1dba3-34c8-45b2-abff-baada752bb7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\gadeu/School/M1 SD/Gestion_de_projet_IA/chiffre_manuscrit/images/un.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation avec un chemin local :\u001b[39;00m\n\u001b[0;32m     52\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/School/M1 SD/Gestion_de_projet_IA/chiffre_manuscrit/images/un.png\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m---> 53\u001b[0m predicted_digit_label, predicted_digit \u001b[38;5;241m=\u001b[39m predict_digit(image_path, model)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Affichage de l'image associée\u001b[39;00m\n\u001b[0;32m     56\u001b[0m example_image \u001b[38;5;241m=\u001b[39m predicted_digit\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)  \u001b[38;5;66;03m# Reshape le vecteur de 784 à 28x28\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m, in \u001b[0;36mpredict_digit\u001b[1;34m(image_path, model)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mPrédit le chiffre dans une image donnée par son chemin local.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mLa normalisation est effectuée dans preprocess_image avant la prédiction.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Prétraiter l'image et normaliser\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m img_vector_normalized \u001b[38;5;241m=\u001b[39m preprocess_image(image_path)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Faire la prédiction avec le modèle\u001b[39;00m\n\u001b[0;32m     42\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img_vector_normalized)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(image_path)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Utiliser `with` pour ouvrir l'image de manière sûre\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(image_path) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[0;32m     20\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convertir en niveaux de gris\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))  \u001b[38;5;66;03m# Redimensionner l'image à 28x28 pixels\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\gadeu/School/M1 SD/Gestion_de_projet_IA/chiffre_manuscrit/images/un.png'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Prétraiter l'image : \n",
    "    1. Charger l'image.\n",
    "    2. Convertir en niveaux de gris.\n",
    "    3. Redimensionner à 28x28 pixels pour correspondre à `load_digits`.\n",
    "    4. Aplatir l'image en un vecteur de 784 éléments.\n",
    "    \"\"\"\n",
    "    # Résoudre le ~ dans le chemin du fichier\n",
    "    image_path = os.path.expanduser(image_path)\n",
    "    \n",
    "    # Utiliser `with` pour ouvrir l'image de manière sûre\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert('L')  # Convertir en niveaux de gris\n",
    "        img = img.resize((28, 28))  # Redimensionner l'image à 28x28 pixels\n",
    "        img_array = np.array(img)  # Convertir en tableau numpy\n",
    "\n",
    "        # Normaliser l'image si nécessaire, par exemple ici en divisant par 255\n",
    "        img_array = 255 - img_array\n",
    "        img_array = img_array / 255.0\n",
    "\n",
    "        # Aplatir l'image en un vecteur de 784 éléments (28x28)\n",
    "        img_vector = img_array.flatten()\n",
    "    \n",
    "    return img_vector.reshape(1, -1)  # Assurez-vous de retourner un tableau 2D\n",
    "\n",
    "def predict_digit(image_path, model):\n",
    "    \"\"\"\n",
    "    Prédit le chiffre dans une image donnée par son chemin local.\n",
    "    La normalisation est effectuée dans preprocess_image avant la prédiction.\n",
    "    \"\"\"\n",
    "    # Prétraiter l'image et normaliser\n",
    "    img_vector_normalized = preprocess_image(image_path)\n",
    "\n",
    "    # Faire la prédiction avec le modèle\n",
    "    predicted_label = model.predict(img_vector_normalized)[0]\n",
    "    print(f\"Chiffre prédit : {predicted_label}\")\n",
    "    \n",
    "    return predicted_label, img_vector_normalized\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "filename = 'finalized_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Exemple d'utilisation avec un chemin local :\n",
    "image_path = os.path.expanduser('~/School/M1 SD/Gestion_de_projet_IA/chiffre_manuscrit/images/un.png') \n",
    "predicted_digit_label, predicted_digit = predict_digit(image_path, model)\n",
    "\n",
    "# Affichage de l'image associée\n",
    "example_image = predicted_digit.reshape(28, 28)  # Reshape le vecteur de 784 à 28x28\n",
    "plt.imshow(example_image, cmap=\"binary\", interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Le chiffre prédit est : {predicted_digit_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2b7fd-72eb-4072-9be8-18c0c2587f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11825d05-08c1-4ca0-8e57-a9cf411ae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14202c49-59d0-4e6c-b603-cc38f417b88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiffre prédit : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chiffre prédit est : 7\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Prétraiter l'image : \n",
    "    1. Charger l'image.\n",
    "    2. Convertir en niveaux de gris.\n",
    "    3. Redimensionner à 28x28 pixels pour correspondre à `load_digits`.\n",
    "    4. Appliquer la binarisation d'Otsu.\n",
    "    5. Aplatir l'image en un vecteur de 784 éléments.\n",
    "    \"\"\"\n",
    "    # Résoudre le ~ dans le chemin du fichier\n",
    "    image_path = os.path.expanduser(image_path)\n",
    "    \n",
    "    # Utiliser `with` pour ouvrir l'image de manière sûre\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert('L')  # Convertir en niveaux de gris\n",
    "        img = img.resize((28, 28))  # Redimensionner l'image à 28x28 pixels\n",
    "        img_array = np.array(img)  # Convertir en tableau numpy\n",
    "\n",
    "        # Application de la binarisation d'Otsu\n",
    "        threshold_value = threshold_otsu(img_array)\n",
    "        img_array_binary = img_array > threshold_value  # Binarisation (True pour blanc, False pour noir)\n",
    "\n",
    "        # Aplatir l'image binaire en un vecteur de 784 éléments\n",
    "        img_vector = img_array_binary.flatten().astype(int)  # Convertir en 0 et 1\n",
    "    \n",
    "    return img_vector.reshape(1, -1)  # Assurez-vous de retourner un tableau 2D\n",
    "\n",
    "def predict_digit(image_path, model):\n",
    "    \"\"\"\n",
    "    Prédit le chiffre dans une image donnée par son chemin local.\n",
    "    La binarisation est effectuée dans preprocess_image avant la prédiction.\n",
    "    \"\"\"\n",
    "    # Prétraiter l'image et binariser\n",
    "    img_vector_binary = preprocess_image(image_path)\n",
    "\n",
    "    # Faire la prédiction avec le modèle\n",
    "    predicted_label = model.predict(img_vector_binary)[0]\n",
    "    print(f\"Chiffre prédit : {predicted_label}\")\n",
    "    \n",
    "    return predicted_label, img_vector_binary\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "filename = 'finalized_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Exemple d'utilisation avec un chemin local :\n",
    "image_path = os.path.expanduser('~/School/M1 SD/Gestion_de_projet_IA/chiffre_manuscrit/images/un.png') \n",
    "predicted_digit_label, predicted_digit = predict_digit(image_path, model)\n",
    "\n",
    "# Affichage de l'image associée\n",
    "example_image = predicted_digit.reshape(28, 28)  # Reshape le vecteur de 784 à 28x28\n",
    "plt.imshow(example_image, cmap=\"binary\", interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Le chiffre prédit est : {predicted_digit_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e2a7e-12f0-4107-aeb5-0d80bfacd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.*;\n",
    "import java.util.*;\n",
    "\n",
    "public class SVMModel {\n",
    "\n",
    "    private double[][] supportVectors;  // Vecteurs de support\n",
    "    private double[] coefficients;      // Coefficients associés aux vecteurs de support\n",
    "    private double bias;               // Le biais (intercept)\n",
    "\n",
    "    // Charger le modèle depuis des fichiers externes\n",
    "    public SVMModel(String supportVectorsFile, String coefficientsFile, String interceptFile) throws IOException {\n",
    "        this.supportVectors = loadMatrix(supportVectorsFile);\n",
    "        this.coefficients = loadVector(coefficientsFile);\n",
    "        this.bias = loadBias(interceptFile);\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger une matrice (vecteurs de support)\n",
    "    private double[][] loadMatrix(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<double[]> lines = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            String[] values = line.split(\" \");\n",
    "            double[] row = new double[values.length];\n",
    "            for (int i = 0; i < values.length; i++) {\n",
    "                row[i] = Double.parseDouble(values[i]);\n",
    "            }\n",
    "            lines.add(row);\n",
    "        }\n",
    "        br.close();\n",
    "        return lines.toArray(new double[0][]);\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger un vecteur (coefficients)\n",
    "    private double[] loadVector(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<Double> list = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            list.add(Double.parseDouble(line));\n",
    "        }\n",
    "        br.close();\n",
    "        double[] vector = new double[list.size()];\n",
    "        for (int i = 0; i < list.size(); i++) {\n",
    "            vector[i] = list.get(i);\n",
    "        }\n",
    "        return vector;\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger le biais\n",
    "    private double loadBias(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        String line = br.readLine();\n",
    "        br.close();\n",
    "        return Double.parseDouble(line);\n",
    "    }\n",
    "\n",
    "    // Prédiction pour une nouvelle entrée (par exemple, une image transformée en un vecteur)\n",
    "    public double predict(double[] x) {\n",
    "        double result = 0;\n",
    "        for (int i = 0; i < supportVectors.length; i++) {\n",
    "            // Calcul du produit scalaire entre le vecteur de support et l'entrée x\n",
    "            double dotProduct = 0;\n",
    "            for (int j = 0; j < supportVectors[i].length; j++) {\n",
    "                dotProduct += supportVectors[i][j] * x[j];\n",
    "            }\n",
    "            // Ajout au résultat, pondéré par les coefficients\n",
    "            result += coefficients[i] * dotProduct;\n",
    "        }\n",
    "        // Ajouter le biais\n",
    "        result += bias;\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws IOException {\n",
    "        // Charger les fichiers du modèle\n",
    "        SVMModel model = new SVMModel(\"support_vectors.txt\", \"coefficients.txt\", \"intercept.txt\");\n",
    "\n",
    "        // Exemple de prédiction : un nouveau vecteur (image transformée)\n",
    "        double[] newImage = { /* Votre image transformée en vecteur ici */ };\n",
    "        double prediction = model.predict(newImage);\n",
    "        System.out.println(\"Prédiction : \" + prediction);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6a7ce-6697-43aa-ae45-fcc04b2175f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.*;\n",
    "import java.util.*;\n",
    "\n",
    "public class SVM_RBF_Model {\n",
    "\n",
    "    private double[][] supportVectors;  // Vecteurs de support\n",
    "    private double[] alphas;           // Coefficients (alphas) associés aux vecteurs de support\n",
    "    private double bias;               // Le biais (intercept)\n",
    "    private double gamma;              // Paramètre gamma pour le noyau RBF\n",
    "\n",
    "    // Charger le modèle depuis des fichiers externes\n",
    "    public SVM_RBF_Model(String supportVectorsFile, String alphasFile, String biasFile, double gamma) throws IOException {\n",
    "        this.supportVectors = loadMatrix(supportVectorsFile);\n",
    "        this.alphas = loadVector(alphasFile);\n",
    "        this.bias = loadBias(biasFile);\n",
    "        this.gamma = gamma;\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger une matrice (vecteurs de support)\n",
    "    private double[][] loadMatrix(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<double[]> lines = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            String[] values = line.split(\" \");\n",
    "            double[] row = new double[values.length];\n",
    "            for (int i = 0; i < values.length; i++) {\n",
    "                row[i] = Double.parseDouble(values[i]);\n",
    "            }\n",
    "            lines.add(row);\n",
    "        }\n",
    "        br.close();\n",
    "        return lines.toArray(new double[0][]);\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger un vecteur (alphas)\n",
    "    private double[] loadVector(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<Double> list = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            list.add(Double.parseDouble(line));\n",
    "        }\n",
    "        br.close();\n",
    "        double[] vector = new double[list.size()];\n",
    "        for (int i = 0; i < list.size(); i++) {\n",
    "            vector[i] = list.get(i);\n",
    "        }\n",
    "        return vector;\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger le biais\n",
    "    private double loadBias(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        String line = br.readLine();\n",
    "        br.close();\n",
    "        return Double.parseDouble(line);\n",
    "    }\n",
    "\n",
    "    // Calcul de la fonction noyau RBF\n",
    "    private double rbfKernel(double[] x, double[] supportVector) {\n",
    "        double sum = 0;\n",
    "        for (int i = 0; i < x.length; i++) {\n",
    "            sum += (x[i] - supportVector[i]) * (x[i] - supportVector[i]);\n",
    "        }\n",
    "        return Math.exp(-gamma * sum);  // RBF kernel: exp(-gamma * ||x - x_i||^2)\n",
    "    }\n",
    "\n",
    "    // Prédiction pour une nouvelle entrée (image transformée en un vecteur)\n",
    "    public double predict(double[] x) {\n",
    "        double result = 0;\n",
    "        for (int i = 0; i < supportVectors.length; i++) {\n",
    "            // Calcul du noyau RBF entre l'entrée x et le vecteur de support\n",
    "            double kernelValue = rbfKernel(x, supportVectors[i]);\n",
    "            result += alphas[i] * kernelValue;\n",
    "        }\n",
    "        // Ajouter le biais\n",
    "        result += bias;\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws IOException {\n",
    "        // Charger le modèle RBF\n",
    "        SVM_RBF_Model model = new SVM_RBF_Model(\"support_vectors_rbf.txt\", \"alphas_rbf.txt\", \"bias_rbf.txt\", 0.5);\n",
    "\n",
    "        // Exemple de prédiction : un nouveau vecteur (image transformée)\n",
    "        double[] newImage = { /* Votre image transformée en vecteur ici */ };\n",
    "        double prediction = model.predict(newImage);\n",
    "        System.out.println(\"Prédiction : \" + prediction);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddfc32-6715-437b-b4f6-9d32b4e88ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.*;\n",
    "import java.util.*;\n",
    "\n",
    "public class SVM_RBF_Model {\n",
    "\n",
    "    private double[][] supportVectors;  // Vecteurs de support\n",
    "    private double[] alphas;           // Coefficients (alphas) associés aux vecteurs de support\n",
    "    private double bias;               // Le biais (intercept)\n",
    "    private double gamma;              // Paramètre gamma pour le noyau RBF\n",
    "\n",
    "    // Charger le modèle depuis des fichiers externes\n",
    "    public SVM_RBF_Model(String supportVectorsFile, String alphasFile, String biasFile, double gamma) throws IOException {\n",
    "        this.supportVectors = loadMatrix(supportVectorsFile);\n",
    "        this.alphas = loadVector(alphasFile);\n",
    "        this.bias = loadBias(biasFile);\n",
    "        this.gamma = gamma;\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger une matrice (vecteurs de support)\n",
    "    private double[][] loadMatrix(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<double[]> lines = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            String[] values = line.split(\" \");\n",
    "            double[] row = new double[values.length];\n",
    "            for (int i = 0; i < values.length; i++) {\n",
    "                row[i] = Double.parseDouble(values[i]);\n",
    "            }\n",
    "            lines.add(row);\n",
    "        }\n",
    "        br.close();\n",
    "        return lines.toArray(new double[0][]);\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger un vecteur (alphas)\n",
    "    private double[] loadVector(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        List<Double> list = new ArrayList<>();\n",
    "        String line;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            list.add(Double.parseDouble(line));\n",
    "        }\n",
    "        br.close();\n",
    "        double[] vector = new double[list.size()];\n",
    "        for (int i = 0; i < list.size(); i++) {\n",
    "            vector[i] = list.get(i);\n",
    "        }\n",
    "        return vector;\n",
    "    }\n",
    "\n",
    "    // Fonction pour charger le biais\n",
    "    private double loadBias(String file) throws IOException {\n",
    "        BufferedReader br = new BufferedReader(new FileReader(file));\n",
    "        String line = br.readLine();\n",
    "        br.close();\n",
    "        return Double.parseDouble(line);\n",
    "    }\n",
    "\n",
    "    // Calcul du noyau RBF entre un vecteur d'entrée x et un vecteur de support x_i\n",
    "    public double rbfKernel(double[] x, double[] supportVector, double gamma) {\n",
    "        double sum = 0;\n",
    "        for (int i = 0; i < x.length; i++) {\n",
    "            sum += (x[i] - supportVector[i]) * (x[i] - supportVector[i]);\n",
    "        }\n",
    "        return Math.exp(-gamma * sum);  // RBF kernel: exp(-gamma * ||x - x_i||^2)\n",
    "    }\n",
    "\n",
    "    // Prédiction pour une nouvelle entrée (image transformée en vecteur)\n",
    "    public double predict(double[] x) {\n",
    "        double result = 0;\n",
    "        for (int i = 0; i < supportVectors.length; i++) {\n",
    "            // Calcul du noyau RBF entre l'entrée x et le vecteur de support supportVectors[i]\n",
    "            double kernelValue = rbfKernel(x, supportVectors[i], gamma);\n",
    "            // Ajouter la contribution du vecteur de support avec le coefficient alpha\n",
    "            result += alphas[i] * kernelValue;\n",
    "        }\n",
    "        // Ajouter le biais\n",
    "        result += bias;\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws IOException {\n",
    "        // Charger le modèle RBF\n",
    "        SVM_RBF_Model model = new SVM_RBF_Model(\"support_vectors_rbf.txt\", \"alphas_rbf.txt\", \"bias_rbf.txt\", 0.5);\n",
    "\n",
    "        // Exemple de prédiction : un nouveau vecteur (image transformée)\n",
    "        double[] newImage = { /* Votre image transformée en vecteur ici */ };\n",
    "        double prediction = model.predict(newImage);\n",
    "        System.out.println(\"Prédiction : \" + prediction);\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
